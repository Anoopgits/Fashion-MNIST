# -*- coding: utf-8 -*-
"""Fashion -MNIST.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14rtWORGJhOli93LCQ3ar4KUy9XKnyqdX

import the requried library for this project
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
import tensorflow as tf
from tensorflow import keras
from PIL import Image
import os
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from keras.models import Sequential, load_model
from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout,BatchNormalization
from tensorflow.math import confusion_matrix
from sklearn.metrics import accuracy_score
from keras.datasets import fashion_mnist
from tensorflow.keras.callbacks import EarlyStopping

"""load the dataset"""

(x_train,y_train),(x_test,y_test)=fashion_mnist.load_data()

"""This is a dataset of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images. This dataset can be used as a drop-in replacement for MNIST.

The classes are:

Label	Description:

0	T-shirt/top

1	Trouser

2	Pullover

3	Dress

4	Coat

5	Sandal

6	Shirt

7	Sneaker

8	Bag

9	Ankle boot

Returns

Tuple of NumPy arrays: (x_train, y_train), (x_test, y_test).

x_train: uint8 NumPy array of grayscale image data with shapes (60000, 28, 28), containing the training data.

y_train: uint8 NumPy array of labels (integers in range 0-9) with shape (60000,) for the training data.

x_test: uint8 NumPy array of grayscale image data with shapes (10000, 28, 28), containing the test data.

y_test: uint8 NumPy array of labels (integers in range 0-9) with shape (10000,) for the test data.
"""

print(x_train.shape,y_train.shape)
print(x_test.shape,y_test.shape)

"""dataset has grayscale image"""

type(x_train)

print(x_train[0])

"""display the image"""

plt.imshow(x_train[0],cmap='gray')
plt.show()
print(y_train[0])

"""this is Sneaker"""

plt.imshow(x_train[10],cmap='gray')
plt.show()
print(y_train[10])

"""this is t shirt"""

# find the number of class
print(np.unique(y_train))

"""Normalize the value"""

x_train=x_train/255
x_test=x_test/255

print(x_train[0])

"""image data is convert to probability form

Build the neural network
"""

model=Sequential()
model.add(Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)))
model.add(MaxPool2D((2,2)))
model.add(Conv2D(64,(3,3),activation='relu'))
model.add(MaxPool2D((2,2)))
model.add(Flatten())
model.add(Dense(128,activation='relu'))
model.add(Dense(10,activation='softmax'))

model.summary()

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

history=model.fit(x_train,y_train,epochs=10,validation_data=[x_test,y_test],batch_size=32)

plt.plot(history.history['loss'],label='loss')
plt.plot(history.history['val_loss'],label='val_loss')
plt.legend()
plt.show()

plt.plot(history.history['accuracy'],label='accuracy')
plt.plot(history.history['val_accuracy'],label='val_accuracy')
plt.legend()
plt.show()

"""this modelis clearly overfitting

now to add reduce the overfitting by adding the early stopping and drop out and batch normalize concept in model
"""

model=Sequential()
model.add(Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)))
model.add(BatchNormalization())
model.add(MaxPool2D((2,2)))
model.add(Conv2D(64,(3,3),activation='relu'))
model.add(BatchNormalization())
model.add(MaxPool2D((2,2)))
model.add(Flatten())
model.add(Dense(128,activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(10,activation='softmax'))

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

# from tensorflow.kears.callbacks import EarlyStopping
earlystopping=EarlyStopping(monitor='accuracy',patience=5,verbose=1)

history=model.fit(x_train,y_train,epochs=10,batch_size=32,callbacks=[earlystopping])

plt.plot(history.history['loss'],label='loss')
# plt.plot(history.history['val_loss'],label='val_loss')
plt.legend()
plt.show()

plt.plot(history.history['accuracy'],label='accuracy')
# plt.plot(history.history['val_accuracy'],label='val_accuracy')
plt.legend()
plt.show()

# find the accuracy
loss,accuracy=model.evaluate(x_test,y_test)
print(loss,accuracy)

print(x_test.shape)

plt.imshow(x_test[0],cmap='gray')
plt.show()

y_pred=model.predict(x_test)

print(y_pred.shape)

print(y_pred[0])

y_pred_label=[np.argmax(i) for i in y_pred]

print(y_pred_label)

# plot the confusion matrix
cm=confusion_matrix(y_test,y_pred_label)
print(cm)

sns.heatmap(cm,annot=True,fmt='d')
plt.show()



"""# Building the predicting system"""

input_image_path=input('enter the image path')

input_image=cv2.imread(input_image_path)

type(input_image)

print(input_image)

from google.colab.patches import cv2_imshow
cv2_imshow(input_image)
# cv2.waitKey(0

input_image.shape

"""this is RGB image so convert the gray scale image"""

grayscle=cv2.cvtColor(input_image,cv2.COLOR_BGR2GRAY)

grayscle.shape

"""this is convert to gray scale image

resize the image
"""

resize_image=cv2.resize(grayscle,(28,28))

resize_image.shape

cv2_imshow(resize_image)

"""Scale the image"""

resize_image=resize_image/255

type(resize_image)

"""to reshape the channel dimension"""

resize_image=np.reshape(resize_image,(1,28,28))

predict=model.predict(resize_image)

print(predict)

predict_label=np.argmax(predict)

print(predict_label)

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']
print(f"Predicted class index: {predict_label}")
print(f"Predicted class name: {class_names[predict_label]}")

model.save('Fashion-mnist.h5')

